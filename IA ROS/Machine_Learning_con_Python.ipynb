{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning con Python.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh72ca5q0CAB"
      },
      "source": [
        "# 1 El algoritmo K-vecinos (K-nn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koglQxVg0Sx6"
      },
      "source": [
        "Existen multitud de técnicas y algoritmos que podemos utilizar en Machine Learning, como clasificadores Bayesianos o árboles de decisión. Una de las técnicas más sencillas podría ser el método de los **K-vecinos** (o **K-nn** del inglés K-nearest neighbors). La idea de este algoritmo es que la etiqueta de clase que se asigna a un nueva muestra depende de los **k** ejemplos de entrenamiento que son más similares ésta. Esto es, se asigna la etiqueta de clase que más se repite en las k muestras más próximas a la nueva.\n",
        "\n",
        "Si ejecutas el siguiente código podrás ver en una gráfica cómo se sitúan muestras rojas y azules. Teniendo en cuenta un valor de **k=1**, puedes ver que la muestra verde se clasificaría como azul. Para evitar empates, normalmente utilizaremos un número impar para el valor de k."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wA24Ow1z7wR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "a1573877-6651-4f49-ae2c-e4761658644e"
      },
      "source": [
        "import matplotlib.pyplot as plot #si no te funciona en tu entorno, haz un pip install matplotlib\n",
        "\n",
        "red_points = [(1,1), (1,2), (2,4), (2,5), (3,1), (3,3), (4,2), (4,5), (4,7), (5,2), (5,3), (6,3), (7,1), (7,4)]\n",
        "blue_points = [(1,4), (1,7), (2,2), (2,7), (2,8), (3,4), (3,6), (4,4), (4,6), (5,4), (5,5), (5,8), (6,4), (6,5), (7,5)]\n",
        "\n",
        "red_x = [i[0] for i in red_points]\n",
        "red_y = [i[1] for i in red_points]\n",
        "\n",
        "blue_x = [i[0] for i in blue_points]\n",
        "blue_y = [i[1] for i in blue_points]\n",
        "\n",
        "fig=plot.figure()\n",
        "ax=fig.add_axes([0,0,1,1])\n",
        "ax.scatter(red_x, red_y, color='r')\n",
        "ax.scatter(blue_x, blue_y, color='b')\n",
        "ax.scatter([6], [6], color='g', marker=\"x\")\n",
        "ax.set_xlabel('x coordinates')\n",
        "ax.set_ylabel('y coordinates')\n",
        "ax.set_title('Samples')\n",
        "plot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIbwm67D1rWM"
      },
      "source": [
        "El concepto de cercanía entre dos muestras *p* y *q*, cada una de ellas representada como *n* atributos, lo podemos definir como la distancia euclidea entre ambas muestras:\n",
        "\n",
        "$$d(p,q) = \\sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + \\ldots + (p_n - q_n)^2}$$\n",
        "\n",
        "A continuación, vamos a implementar el algoritmo K-nn desde cero, utilizando todos los conocimientos que ya tenemos de Python. Para ello, los pasos que vamos a seguir son los siguientes:\n",
        "\n",
        "1.   Cargar las muestras\n",
        "2.   Convertir los atributos a float\n",
        "3.   Codificar los nombres de las clases en valores enteros\n",
        "4.   Calcular la distancia euclidea\n",
        "5.   Obtener los vecinos más cercanos utilizando la distancia euclidea\n",
        "6.   Realizar predicciones\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjai2X3H3f7N"
      },
      "source": [
        "## 1.1 Cargando el dataset de muestras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iBfqM_4IN-0"
      },
      "source": [
        "El primer paso será implementar la función **load_file** que se encargará de leer los datos de un fichero (en formato csv) y guardarlos en una lista de muestras. Cada muestra estará representada como una lista de atributos, siendo el último de ellos, el nombre de la clase. Como resultado, debemos tener una lista de muestras, donde cada muestra tendrá la forma ['1', '1', 'red']. En primer lugar, **ejecuta el siguiente código** para clonar el repositorio donde está el fichero. A continuación, **completa el código** de la función **load_file**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6BYeO7OOBi4"
      },
      "source": [
        "!git clone https://gitlab.com/ia_gti/machine_learning_python.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djmvaWZR4cwj"
      },
      "source": [
        "from csv import reader\n",
        "\n",
        "def load_file(filename):\n",
        "  \"\"\" Reads a file and stores each line as a sample in a list\n",
        "  Args: \n",
        "    filename: name of the dataset file\n",
        "  Returns:\n",
        "    list of samples, where each sample is: e.g. ['1', '1', 'red']\n",
        "  \"\"\"\n",
        "  #TODO\n",
        "\n",
        "#1. Load dataset\n",
        "filename = 'sample_data//colours.csv'\n",
        "dataset = load_file(filename)\n",
        "print(\"1: \"+str(dataset[0]))\n",
        "\n",
        "print('Se ha cargado el fichero '+ filename+ ' con ', len(dataset),' líneas (muestras) y ', len(dataset[0]), ' columnas (atributos por muestra)')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQJx94xj5a4w"
      },
      "source": [
        "## 1.2 Convirtiendo los atributos a float"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PqUi558JaVf"
      },
      "source": [
        "El siguiente paso será implementar la función **convert_str_to_float**, que se encargará de convertir los atributos de la muestra a floats (excepto el nombre de clase, esto es, las columnas 0 y 1). Esta función recibirá la lista de muestras y una columna a convertir. Como resultado, cada muestra tendrá la forma [1.0, 1.0, 'red']. Utiliza la función **strip** para eliminar las comillas:\n",
        "https://www.programiz.com/python-programming/methods/string/strip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTrP0sZOApsn"
      },
      "source": [
        "ATTRIBUTES = 2\n",
        "\n",
        "def convert_str_to_float(dataset, column):\n",
        "  \"\"\" Converts a string data to float\n",
        "  Args: \n",
        "    dataset: list of samples, where each sample is: e.g. ['1', '1', 'red']\n",
        "    column: column number\n",
        "  \"\"\"\n",
        "  #TODO\n",
        "\n",
        "#2. Convert numerical attributes to floats\n",
        "for i in range(ATTRIBUTES): #i coge valores de 0 y 1\n",
        "  convert_str_to_float(dataset, i)    \n",
        "print(\"2: \"+str(dataset[0]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYhf27AWFu3C"
      },
      "source": [
        "## 1.3 Codificando el nombre de clase a un valor entero"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehEnjQtTJ3qs"
      },
      "source": [
        "A continuación, codificaremos el nombre de las clases a un valor numérico mediante la función **code_str_to_int**. Cuando realizamos predicciones, los valores de clase se suelen representar como valores numéricos (p.e. 0, 1, etc.) en vez de strings (p.e. 'red', 'blue', etc.).\n",
        "\n",
        "Esta función recibirá la lista de muestras con la forma [1.0, 1.0, 'red'] y una columna a convertir (la columna de la clase). Lo que hará esta función será asignar un valor numérico a cada clase y modificar cada muestra para que tenga la forma [1.0, 1.0, 0]. Además, deberá devolver un diccionario con pares clave-valor, donde la clave será el nombre de la clase y el valor su código. En nuestro caso, será {'red': 0, 'blue': 1}. \n",
        "\n",
        "Realiza una implementación genérica para cualquier número y nombre de clases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0PvujUsA0a_"
      },
      "source": [
        "def code_str_to_int(dataset, column):\n",
        "  \"\"\" Converts a string data to int\n",
        "  Args: \n",
        "    dataset: list of samples, where each sample is: e.g. [1.0, 1.0, 'red']\n",
        "    column: column number\n",
        "  Returns:\n",
        "    dictionary of class-int_code, such as { 'red':0, 'blue':1 }\n",
        "  \"\"\"\n",
        "  #TODO\n",
        "\n",
        "#3. Convert class attribute to integer\n",
        "lookup = code_str_to_int(dataset, len(dataset[0])-1)\n",
        "print(\"3: \"+str(lookup))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f_MaNAKF5xa"
      },
      "source": [
        "## 1.4 Calculando la distancia entre dos muestras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrv3nYBcLIfu"
      },
      "source": [
        "Llegados a este punto, vamos a implementar la función **euclidean_distance** que recibirá dos muestras y devolverá la distancia euclídea entre ellas. Recuerda que la distancia euclídea se calcula según la siguiente fórmula:\n",
        "\n",
        "$$d(p,q) = \\sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + \\ldots + (p_n - q_n)^2}$$\n",
        "\n",
        "Realiza una implementación genérica para cualquier número de atributos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnFEbRjNA8VP"
      },
      "source": [
        "from math import sqrt\n",
        "\n",
        "def euclidean_distance(sample, dataset_sample):\n",
        "  \"\"\" Calculates the Euclidean distance between two samples (vectors)\n",
        "  Args: \n",
        "    sample: sample to classify, such as [4, 3]\n",
        "    dataset_sample: sample of the dataset, such as [1.0, 1.0, 1]\n",
        "  Returns:\n",
        "    euclidean_distance between both samples, such as 3.61\n",
        "  \"\"\"\n",
        "  #TODO\n",
        "\n",
        "# sample to classify\n",
        "sample = (4, 3)\n",
        "\n",
        "for row in dataset:\n",
        "\tdistance = euclidean_distance(sample, row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T42MgIb_GD0S"
      },
      "source": [
        "## 1.5 Encontrando los k-vecinos más silimares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52FEpsc6LkXH"
      },
      "source": [
        "A continuación, implementaremos la función **get_neighbors**, la cual recibirá la lista de muestras (que llamaremos `train`), una muestra a clasificar y un número *k* y devolverá una lista con los *k* vecimos más similares a la muestra. Esta función tendrá que llamar a la función anterior **euclidean_distance** por cada muestra de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0thRMmtoByiJ"
      },
      "source": [
        "def get_neighbors(train, test, k):\n",
        "  \"\"\" Obtains the k most similar neighbors\n",
        "  Args: \n",
        "    train: list of samples\n",
        "    test: sample to classify\n",
        "    k: number of nearest neighbors\n",
        "  Returns:\n",
        "    list of the k nearest neighbors\n",
        "  \"\"\"\n",
        "  #TODO\n",
        "\n",
        "# define k parameter\n",
        "num_neighbors = 5\n",
        "\n",
        "# sample to classify\n",
        "sample = (6, 2)\n",
        "\n",
        "#5. Get k nearest neighbours using euclidean_distance function\n",
        "neighbors = get_neighbors(dataset, sample, num_neighbors)\n",
        "\n",
        "print(neighbors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIeSrdrRGJ18"
      },
      "source": [
        "## 1.6 Realizando la predicción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uivfbNH_MSFf"
      },
      "source": [
        "Finalmente, realizaremos la predicción mediante la función **predict_class**. Realmente, el código de esta función podría ir dentro de la función anterior, pero hemos preferido dejarlo separado. Básicamente, tendrá que calcular cuál es la clase más repetida a partir los *k-vecinos* más próximos que ha encontrado en la función anterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM-WJSy9GSIs"
      },
      "source": [
        "def predict_class(neighbors, lookup):    \n",
        "  \"\"\" Obtains the predicted class for the test sample\n",
        "  Args:\n",
        "    neighbours: list of k nearest neighbors \n",
        "    lookup: dictionary of classes and int_code such as {'blue': 0, 'red': 1}\n",
        "  Returns:\n",
        "    name of the predicted class \n",
        "  \"\"\"\n",
        "  #TODO\n",
        "\n",
        "#6. Predict the class label\n",
        "label = predict_class(neighbors, lookup)\n",
        "print('Data=%s, Predicted: %s' % (sample, label))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqryWHHAHOls"
      },
      "source": [
        "## 1.7 Ejercicio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okPvmVDRH3sr"
      },
      "source": [
        "Una vez tienes las funciones implementadas, genera un fichero .py (si no lo has hecho ya) y modifica las funciones para entrenar un modelo a partir del dataset de flores de iris. Quita 10 muestras y utilízalas para probar tu clasificador.\n",
        "\n",
        "Utiliza un fichero a parte que importe el paquete implementado y prueba su funcionamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWcD0XhntpwA"
      },
      "source": [
        "# 2 K-nn usando scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RNM3qaLt0q3"
      },
      "source": [
        "Una vez has implementado el algoritmo K-nn desde 0, vamos a utilizar la librería **scikit-learn** que es una librería de Machine Learning para Python (https://scikit-learn.org/stable/). Esta librería nos ofrece muchas funcionalidades implementadas, de manera que podemos trabajar con distintos algoritmos de Machine Learning de manera sencilla. Si quieres trabajar en tu máquina, para agregarla en tu entorno virtual de py3env, puedes ejecutar el siguiente comando:\n",
        "```python\n",
        "pip install scikit-learn\n",
        "```\n",
        "\n",
        "Aunque utilizaremos esta librería más adelante (y también en otras asignaturas), a continuación tienes un ejemplo muy sencillo de cómo podemos utilizar el clasificador K-nn que tiene ya implementado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhMD5qDv6aWo",
        "outputId": "d62b2275-b9d1-4bd1-b554-7a0cd0135344"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "X = [(1,1), (1,2), (2,4), (2,5), (3,1), (3,3), (4,2), (4,5), (4,7), (5,2), (5,3), (6,3), (7,1), (7,4), (1,4), (1,7), (2,2), (2,7), (2,8), (3,4), (3,6), (4,4), (4,6), (5,4), (5,5), (5,8), (6,4), (6,5), (7,5)]\n",
        "y = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
        "\n",
        "# define k parameter\n",
        "k = 5\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=k)\n",
        "neigh.fit(X, y)\n",
        "\n",
        "# sample to classify\n",
        "sample = (6, 2)\n",
        "\n",
        "prediction = neigh.predict([sample])\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}